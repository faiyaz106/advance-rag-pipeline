{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "105f5ecd-a337-4972-9717-02d0a6927950",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "import os\n",
    "import openai\n",
    "openai.api_key = utils.get_openai_api_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ff33a2b9-b939-43b6-b4be-668e9d4f4167",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader(\n",
    "    input_files=[\"./documents/1040.pdf\"]\n",
    ").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7b110521-3180-4aaf-9c66-6dcee704f74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> \n",
      "\n",
      "114 \n",
      "\n",
      "<class 'llama_index.core.schema.Document'>\n",
      "Doc ID: 83e783ac-f932-4f2e-960c-d2330a9e4119\n",
      "Text: Userid: CPM Schema:  i1040xLeadpct: 100% Pt. size: 10  Draft  Ok\n",
      "to Print AH XSL/XML Fileid: … ions/i1040/2023/a/xml/cycle08/source\n",
      "(Init. & Date) _______ Page 1 of 114  13:55 - 27-Dec-2023 The type and\n",
      "rule above prints on all proofs including departmental reproduction\n",
      "proofs. MUST be removed before printing. Dec 27, 2023 Cat. No. 24811V\n",
      "Futur ...\n"
     ]
    }
   ],
   "source": [
    "print(type(documents), \"\\n\")\n",
    "print(len(documents), \"\\n\")\n",
    "print(type(documents[0]))\n",
    "print(documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "de007c3f-e09c-4a03-8cd9-b4a78791eb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Basic RAG pipeline\n",
    "from llama_index.core import Document\n",
    "\n",
    "document = Document(text=\"\\n\\n\".join([doc.text for doc in documents]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4faf8366-ebae-4488-9ce7-5e037d1cfb7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s4/2ckbp3v55651lb5c8j__q7dw0000gn/T/ipykernel_33302/3391627733.py:6: DeprecationWarning: Call to deprecated class method from_defaults. (ServiceContext is deprecated, please use `llama_index.settings.Settings` instead.) -- Deprecated since version 0.10.0.\n",
      "  service_context = ServiceContext.from_defaults(llm=llm, embed_model=\"local:BAAI/bge-small-en-v1.5\")\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core import ServiceContext\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1)\n",
    "service_context = ServiceContext.from_defaults(llm=llm, embed_model=\"local:BAAI/bge-small-en-v1.5\")\n",
    "index = VectorStoreIndex.from_documents([document],service_context=service_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9e3e174f-efb2-4471-8194-09c0963e47ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import build_sentence_window_index\n",
    "\n",
    "sentence_index = build_sentence_window_index(\n",
    "    document,\n",
    "    llm,\n",
    "    embed_model=\"local:BAAI/bge-small-en-v1.5\",\n",
    "    save_dir=\"sentence_index\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ccf4a465-eba6-4c4f-afca-f70f5c119056",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_sentence_window_query_engine\n",
    "sentence_window_engine = get_sentence_window_query_engine(sentence_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "871f5606-07d0-408c-9035-330e23d15147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To compute the student loan interest deduction, you need to follow these steps:\n",
      "1. Multiply the total interest paid on qualified student loans in 2023 by the total contributions by certain chaplains to section 403(b) plans.\n",
      "2. Subtract the result from step 1 from the total interest paid on qualified student loans in 2023.\n",
      "3. Enter the final result on Line 21 of Schedule 1 and ensure not to include this amount in any other deduction on your return.\n",
      "4. If applicable, figure any write-in adjustments to be entered on Schedule 1, line 24z as per the instructions.\n",
      "5. Make sure to review the Exception in the instructions to determine if you can use the worksheet provided instead of Pub. 970 to calculate your deduction.\n"
     ]
    }
   ],
   "source": [
    "window_response = sentence_window_engine.query(\n",
    "   \"What is the workflow to compute student loan interest deduction \")\n",
    "print(str(window_response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5eec930-d7f6-45a3-94ed-1eb155cf1900",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5720015-c3ff-4efe-ae7a-2177373b7d61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3fb01c1b-d00b-4a97-9c82-f5166b48e905",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085baba1-c85d-42a8-8b07-164f27c78c6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06876f62-06c2-4d00-bde3-15779b309c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from trulens_eval import Feedback, Select\n",
    "from trulens_eval.feedback.provider.openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f4db6308-5d42-4ee4-8fff-bb09678b9ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_openai_api_key():\n",
    "    _ = load_dotenv(find_dotenv())\n",
    "    return os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "44065605-50db-4047-9136-d678d3824a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval.feedback.provider.openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3348d8b2-ccfe-424f-8403-00c6d454e044",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feedback function `relevance_with_cot_reasons` has `self` as argument. Perhaps it is static method or its Provider class was not initialized?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ In Answer Relevance, input self will be set to __record__.main_input or `Select.RecordInput` .\n",
      "✅ In Answer Relevance, input prompt will be set to __record__.main_output or `Select.RecordOutput` .\n"
     ]
    }
   ],
   "source": [
    "qa_relevance = (\n",
    "    Feedback(OpenAI.relevance_with_cot_reasons, name=\"Answer Relevance\")\n",
    "    .on_input_output()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9b61feb5-2873-4fb9-9ca4-cc527f78df90",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'grounded'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m provider\u001b[38;5;241m=\u001b[39m OpenAI\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgrounded\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'grounded'"
     ]
    }
   ],
   "source": [
    "provider= OpenAI\n",
    "import grounded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "657d57f6-fed4-4654-9d23-32514a510ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feedback function `groundedness_measure_with_cot_reasons` has `self` as argument. Perhaps it is static method or its Provider class was not initialized?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ In Groundedness, input self will be set to __record__.app.query.rets.source_nodes[:].node.text .\n",
      "✅ In Groundedness, input source will be set to __record__.main_output or `Select.RecordOutput` .\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "grounded_statements_aggregator",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m provider\u001b[38;5;241m=\u001b[39m OpenAI\n\u001b[1;32m      2\u001b[0m groundedness \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m      3\u001b[0m     Feedback(provider\u001b[38;5;241m.\u001b[39mgroundedness_measure_with_cot_reasons, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGroundedness\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;241m.\u001b[39mon(TruLlama\u001b[38;5;241m.\u001b[39mselect_source_nodes()\u001b[38;5;241m.\u001b[39mnode\u001b[38;5;241m.\u001b[39mtext)\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;241m.\u001b[39mon_output()\n\u001b[0;32m----> 6\u001b[0m         \u001b[38;5;241m.\u001b[39maggregate(\u001b[43mprovider\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrounded_statements_aggregator\u001b[49m)\n\u001b[1;32m      7\u001b[0m )\n",
      "File \u001b[0;32m~/rag/lib/python3.9/site-packages/pydantic/_internal/_model_construction.py:242\u001b[0m, in \u001b[0;36mModelMetaclass.__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m rebuilt_validator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    240\u001b[0m             \u001b[38;5;66;03m# In this case, a validator was built, and so `__pydantic_core_schema__` should now be set\u001b[39;00m\n\u001b[1;32m    241\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__pydantic_core_schema__\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 242\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(item)\n",
      "\u001b[0;31mAttributeError\u001b[0m: grounded_statements_aggregator"
     ]
    }
   ],
   "source": [
    "provider= OpenAI\n",
    "groundedness = (\n",
    "    Feedback(provider.groundedness_measure_with_cot_reasons, name=\"Groundedness\")\n",
    "        .on(TruLlama.select_source_nodes().node.text)\n",
    "        .on_output()\n",
    "        .aggregate(provider.grounded_statements_aggregator)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7b8f8806-e3b8-4871-a1ef-0074361f1c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval import Feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "edad5b0b-2109-47fa-919b-d49112b0b00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import ServiceContext, VectorStoreIndex, StorageContext\n",
    "from llama_index.core.node_parser import SentenceWindowNodeParser\n",
    "from llama_index.core.indices.postprocessor import MetadataReplacementPostProcessor\n",
    "from llama_index.core.indices.postprocessor import SentenceTransformerRerank\n",
    "from llama_index.core import load_index_from_storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ac680bbb-fb77-4f65-98c8-d9ba8d6fc5dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feedback function `groundedness_measure_with_cot_reasons` has `self` as argument. Perhaps it is static method or its Provider class was not initialized?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ In Groundedness, input self will be set to __record__.app.retrieve.rets.collect() .\n",
      "✅ In Groundedness, input source will be set to __record__.main_output or `Select.RecordOutput` .\n"
     ]
    }
   ],
   "source": [
    "f_groundedness = (\n",
    "    Feedback(provider.groundedness_measure_with_cot_reasons, name = \"Groundedness\")\n",
    "    .on(Select.RecordCalls.retrieve.rets.collect())\n",
    "    .on_output()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5eba5641-d769-413b-843d-a4fbeb6ada07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feedback function `groundedness_measure_with_cot_reasons` has `self` as argument. Perhaps it is static method or its Provider class was not initialized?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ In Groundedness, input self will be set to __record__.app.query.rets.source_nodes[:].node.text .\n",
      "✅ In Groundedness, input source will be set to __record__.main_output or `Select.RecordOutput` .\n"
     ]
    }
   ],
   "source": [
    "groundedness = (\n",
    "    Feedback(provider.groundedness_measure_with_cot_reasons, name=\"Groundedness\")\n",
    "        .on(TruLlama.select_source_nodes().node.text)\n",
    "        .on_output()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "373f8841-753d-4b4f-a583-bf93d1065a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__abstractmethods__',\n",
       " '__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__class_getitem__',\n",
       " '__class_vars__',\n",
       " '__copy__',\n",
       " '__deepcopy__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__fields_set__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__get_pydantic_core_schema__',\n",
       " '__get_pydantic_json_schema__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__orig_bases__',\n",
       " '__parameters__',\n",
       " '__pretty__',\n",
       " '__private_attributes__',\n",
       " '__pydantic_complete__',\n",
       " '__pydantic_core_schema__',\n",
       " '__pydantic_custom_init__',\n",
       " '__pydantic_decorators__',\n",
       " '__pydantic_extra__',\n",
       " '__pydantic_fields_set__',\n",
       " '__pydantic_generic_metadata__',\n",
       " '__pydantic_init_subclass__',\n",
       " '__pydantic_parent_namespace__',\n",
       " '__pydantic_post_init__',\n",
       " '__pydantic_private__',\n",
       " '__pydantic_root_model__',\n",
       " '__pydantic_serializer__',\n",
       " '__pydantic_validator__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__repr_args__',\n",
       " '__repr_name__',\n",
       " '__repr_str__',\n",
       " '__rich_repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__signature__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_calculate_keys',\n",
       " '_check_frozen',\n",
       " '_construct_source_data',\n",
       " '_copy_and_set_values',\n",
       " '_default_selectors',\n",
       " '_extract_selection',\n",
       " '_get_value',\n",
       " '_is_protocol',\n",
       " '_iter',\n",
       " '_next_unselected_arg_name',\n",
       " '_print_guessed_selector',\n",
       " 'aggregate',\n",
       " 'check_selectors',\n",
       " 'construct',\n",
       " 'copy',\n",
       " 'dict',\n",
       " 'evaluate_deferred',\n",
       " 'extract_selection',\n",
       " 'formatted_objects',\n",
       " 'from_orm',\n",
       " 'get_class',\n",
       " 'json',\n",
       " 'load',\n",
       " 'model_computed_fields',\n",
       " 'model_config',\n",
       " 'model_construct',\n",
       " 'model_copy',\n",
       " 'model_dump',\n",
       " 'model_dump_json',\n",
       " 'model_extra',\n",
       " 'model_fields',\n",
       " 'model_fields_set',\n",
       " 'model_json_schema',\n",
       " 'model_parametrized_name',\n",
       " 'model_post_init',\n",
       " 'model_rebuild',\n",
       " 'model_validate',\n",
       " 'model_validate_json',\n",
       " 'model_validate_strings',\n",
       " 'name',\n",
       " 'of_class',\n",
       " 'of_feedback_definition',\n",
       " 'of_object',\n",
       " 'on',\n",
       " 'on_default',\n",
       " 'on_input',\n",
       " 'on_input_output',\n",
       " 'on_output',\n",
       " 'on_prompt',\n",
       " 'on_response',\n",
       " 'parse_file',\n",
       " 'parse_obj',\n",
       " 'parse_raw',\n",
       " 'replace',\n",
       " 'run',\n",
       " 'run_and_log',\n",
       " 'schema',\n",
       " 'schema_json',\n",
       " 'sig',\n",
       " 'update',\n",
       " 'update_forward_refs',\n",
       " 'validate']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(Feedback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cbd14999-a246-4237-80b9-604535d73cb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mFeedback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mimp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Optional[Callable]'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0magg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Optional[Callable]'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtru_class_info\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrulens_eval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyschema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mClass\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mimplementation\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrulens_eval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyschema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrulens_eval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyschema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0maggregator\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrulens_eval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyschema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrulens_eval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyschema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcombinations\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrulens_eval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeedback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFeedbackCombinations\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0mFeedbackCombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPRODUCT\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'product'\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfeedback_definition_id\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mif_exists\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrulens_eval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLens\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mif_missing\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrulens_eval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeedback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFeedbackOnMissingParameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0mFeedbackOnMissingParameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mERROR\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'error'\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mselectors\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrulens_eval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLens\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msupplied_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mhigher_is_better\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Feedback function container. \n",
       "\n",
       "Typical usage is to specify a feedback implementation function from a\n",
       "[Provider][trulens_eval.feedback.provider.Provider] and the mapping of\n",
       "selectors describing how to construct the arguments to the implementation:\n",
       "\n",
       "Example:\n",
       "    ```python\n",
       "    from trulens_eval import Feedback\n",
       "    from trulens_eval import Huggingface\n",
       "    hugs = Huggingface()\n",
       "    \n",
       "    # Create a feedback function from a provider:\n",
       "    feedback = Feedback(\n",
       "        hugs.language_match # the implementation\n",
       "    ).on_input_output() # selectors shorthand\n",
       "    ```\n",
       "\u001b[0;31mInit docstring:\u001b[0m\n",
       "Create a new model by parsing and validating input data from keyword arguments.\n",
       "\n",
       "Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n",
       "validated to form a valid model.\n",
       "\n",
       "`self` is explicitly positional-only to allow `self` as a field name.\n",
       "\u001b[0;31mFile:\u001b[0m           ~/rag/lib/python3.9/site-packages/trulens_eval/feedback/feedback.py\n",
       "\u001b[0;31mType:\u001b[0m           ModelMetaclass\n",
       "\u001b[0;31mSubclasses:\u001b[0m     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Feedback?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2c9e34-efb5-4e36-86a8-e75bcc6a9bf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
